{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Running Regression Models for MLP + LSTM</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\13473\\\\Desktop\\\\e4040-2020Fall-Project-WNZH-jr4001-xy2419-gl2664\\\\Ipynbs To Run'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_path = r'../'\n",
    "os.chdir(wd_path)\n",
    "wd_path=os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = 'complete_universe_cleaned_normalized_jonn.csv'\n",
    "auto_encoder_data = \"Autoencoder_transformed_43_dim_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 45.088263750076294 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df = pd.read_csv(normalized_data ,dtype={'COMNAM':str,'NCUSIP':str,'PERMNO':str,'PERMCO':str,'SICCD':str,'TICKER_PERMNO':str},low_memory=False,index_col=0)\n",
    "df['DATE'] = pd.to_datetime(df['DATE'],format='%Y-%m-%d')\n",
    "df = df.reset_index()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "auto = pd.read_csv(auto_encoder_data,low_memory=False,index_col=0)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier_cols = ['DATE','COMNAM','NCUSIP','PERMNO','PERMCO','SICCD','TICKER_PERMNO']\n",
    "cross_sectional_cols=['accru', 'adv_sale', 'aftret_eq', 'aftret_equity','aftret_invcapx', 'at_tu', 'bm', 'CAPEI', 'capital_rat', 'cash_debt',\n",
    "       'cash_lt', 'cash_rat', 'cfm', 'curr_debt', 'curr_rat', 'de_rat','debt_assets', 'debt_at', 'debt_capit', 'debt_ebitd', 'debt_invcap',\n",
    "       'divyield', 'dltt_be', 'equity_invcap', 'evm', 'gpm', 'GProf', 'intcov','intcov_rat', 'invt_act', 'lt_debt', 'lt_ppent', 'npm', 'ocf_lct',\n",
    "       'opmad', 'opmbd', 'pay_tu', 'pcf', 'pe_ex', 'pe_inc', 'pretret_earnat','pretret', 'profit_lct', 'ps', 'ptb', 'ptpm', 'quick_rat', 'rd_sale',\n",
    "       'rect_act', 'rect_tu', 'roa', 'roce', 'roe', 'sale_equity','sale_invcap', 'short_debt', 'staff_sale', 'totdebt_invcap']\n",
    "sector_cols = ['Agriculture, Forestry and Fishing', 'Construction','Finance, Insurance', 'Manufacturing', 'Mining', 'Nonclassifiable',\n",
    "       'Public Administration', 'Real Estate', 'Retail Trade', 'Services','Transportation, Communications, Electric, Gas and Sanitary service',\n",
    "       'Wholesale Trade', 'not used']\n",
    "time_series_cols= ['m-12','m-11', 'm-10', 'm-9', 'm-8', 'm-7', 'm-6', 'm-5', 'm-4', 'm-3', 'm-2','m-1']\n",
    "Y = ['m+1']\n",
    "returns =  ['m-12','m-11', 'm-10', 'm-9', 'm-8', 'm-7', 'm-6', 'm-5', 'm-4', 'm-3', 'm-2','m-1','m+1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([df[identifier_cols],auto,df[returns]], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "del auto \n",
    "df = None\n",
    "auto = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_sectional_cols = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10',\n",
    "       '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22',\n",
    "       '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34',\n",
    "       '35', '36', '37', '38', '39', '40', '41', '42']\n",
    "time_series_cols = ['m-12', 'm-11', 'm-10',\n",
    "       'm-9', 'm-8', 'm-7', 'm-6', 'm-5', 'm-4', 'm-3', 'm-2', 'm-1']\n",
    "Y = ['m+1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cross_sectional_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(time_series_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Concatenate, Input, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Model 4: LSTM + MLP Regression'''\n",
    "time_series_inputs = Input(shape=(12,1))\n",
    "cross_sectional_inputs = Input(shape=(43,))\n",
    "\n",
    "h1_rets=LSTM(units=50, return_sequences=True)(time_series_inputs)\n",
    "time_series_output=LSTM(units=30, return_sequences=False)(h1_rets) \n",
    "\n",
    "combined_features = Concatenate()([cross_sectional_inputs, time_series_output])\n",
    "\n",
    "h1=Dense(128, activation='relu')(combined_features)\n",
    "h2=Dense(64, activation='relu')(h1)\n",
    "h3=Dense(32, activation='relu')(h2)\n",
    "outputs=Dense(1, activation='sigmoid')(h3)\n",
    "\n",
    "hybrid_model2=tf.keras.Model(inputs=[cross_sectional_inputs,time_series_inputs], outputs=outputs)\n",
    "\n",
    "opt=tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.005,\n",
    ")\n",
    "hybrid_model2.compile(\n",
    "    optimizer=opt, loss='binary_crossentropy',metrics=['binary_crossentropy','mean_squared_error','mean_absolute_error','mean_absolute_percentage_error']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = new_df['DATE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "x = [new_df[cross_sectional_cols].values,new_df[time_series_cols].values]\n",
    "y = new_df[Y].values[:,0]\n",
    "\n",
    "for dt in dates[119:]:\n",
    "    end_date = pd.to_datetime(dt)\n",
    "    start_date = pd.to_datetime(pd.to_datetime(dt) - relativedelta(years=10))\n",
    "    print(start_date,end_date)\n",
    "    \n",
    "    mask_train=(new_df[['DATE']]>=start_date) & (new_df[['DATE']]<=end_date)\n",
    "    \n",
    "    x_train, y_train=[i[mask_train['DATE'],:] for i in x], y[mask_train['DATE']]\n",
    "    \n",
    "    hybrid_model2=tf.keras.Model(inputs=[cross_sectional_inputs,time_series_inputs], outputs=outputs)\n",
    "\n",
    "    opt=tf.keras.optimizers.Adam(\n",
    "        learning_rate=0.005,\n",
    "    )\n",
    "    hybrid_model2.compile(\n",
    "        optimizer=opt, loss='binary_crossentropy')\n",
    "    \n",
    "    mcp_save = ModelCheckpoint(os.path.join(wd_path,'hdf5_files\\hybrid_reg_model_w_auto_train_period_'+str(start_date.month)+'_'+str(start_date.year)+'_'+str(end_date.month)+'_'+str(end_date.year)+'.hdf5'), save_best_only=True, monitor='val_loss', mode='min') \n",
    "    \n",
    "    history_hybrid2=hybrid_model2.fit(\n",
    "        x=x_train, y=y_train, batch_size=512, epochs=3, verbose=1, \n",
    "        callbacks=[mcp_save],\n",
    "        validation_split=0.1\n",
    "    )\n",
    "    \n",
    "    del hybrid_model2\n",
    "    del history_hybrid2\n",
    "    del x_train\n",
    "    del y_train\n",
    "    gc.collect()\n",
    "    hybrid_model2 = None\n",
    "    history_hybrid2 = None\n",
    "    x_train = None\n",
    "    y_train = None\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
