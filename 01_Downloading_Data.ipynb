{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pydrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(props):\n",
    "    start_mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
    "    NAlist = [] # Keeps track of columns that have missing values filled in. \n",
    "    for col in props.columns:\n",
    "        if props[col].dtype != object:  # Exclude strings\n",
    "            \n",
    "            # Print current column type\n",
    "            print(\"******************************\")\n",
    "            print(\"Column: \",col)\n",
    "            print(\"dtype before: \",props[col].dtype)\n",
    "            \n",
    "            # make variables for Int, max and min\n",
    "            IsInt = False\n",
    "            mx = props[col].max()\n",
    "            mn = props[col].min()\n",
    "            \n",
    "            # Integer does not support NA, therefore, NA needs to be filled\n",
    "            if not np.isfinite(props[col]).all(): \n",
    "                NAlist.append(col)\n",
    "                props[col].fillna(mn-1,inplace=True)  \n",
    "                   \n",
    "            # test if column can be converted to an integer\n",
    "            asint = props[col].fillna(0).astype(np.int64)\n",
    "            result = (props[col] - asint)\n",
    "            result = result.sum()\n",
    "            if result > -0.01 and result < 0.01:\n",
    "                IsInt = True\n",
    "\n",
    "            \n",
    "            # Make Integer/unsigned Integer datatypes\n",
    "            if IsInt:\n",
    "                if mn >= 0:\n",
    "                    if mx < 255:\n",
    "                        props[col] = props[col].astype(np.uint8)\n",
    "                    elif mx < 65535:\n",
    "                        props[col] = props[col].astype(np.uint16)\n",
    "                    elif mx < 4294967295:\n",
    "                        props[col] = props[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        props[col] = props[col].astype(np.uint64)\n",
    "                else:\n",
    "                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n",
    "                        props[col] = props[col].astype(np.int8)\n",
    "                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n",
    "                        props[col] = props[col].astype(np.int16)\n",
    "                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n",
    "                        props[col] = props[col].astype(np.int32)\n",
    "                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n",
    "                        props[col] = props[col].astype(np.int64)    \n",
    "            \n",
    "            # Make float datatypes 32 bit\n",
    "            else:\n",
    "                props[col] = props[col].astype(np.float32)\n",
    "            \n",
    "            # Print new column type\n",
    "            print(\"dtype after: \",props[col].dtype)\n",
    "            print(\"******************************\")\n",
    "    \n",
    "    # Print final result\n",
    "    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
    "    mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage is: \",mem_usg,\" MB\")\n",
    "    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
    "    return props, NAlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "\n",
    "gauth = GoogleAuth()\n",
    "gauth.LocalWebserverAuth() \n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {'WRDS_Financial_Ratios_Monthly.zip':'1sR3oAOjKyzIxYttotJrzMmhrShNIV1zf',\n",
    "         #'WRDS_ALL_PRICE_RETURN_DATA_Daily.zip':'1Fp6lTSOHlEokJsAFtb_MU8onFAN-0Bh8',\n",
    "         'WRDS_ALL_PRICE_RETURN_DATA_Monthly.zip':'1_ESds4Ede3Zke896hl1d4c3iy8SVR-Yc',\n",
    "         'WRDS_constiuents1968_2020_output_universe.zip':'1veIbnyv4n3hqBYrQo5ovBoc1aGXdFygc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name, id in files.items():\n",
    "    print(file_name)\n",
    "    data = drive.CreateFile({'id': id})\n",
    "    data.GetContentFile(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "for file_name, id in files.items():\n",
    "    print(file_name)\n",
    "    shutil.unpack_archive(file_name, './data')\n",
    "    os.remove(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Start here if you already have the data...</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filenames = ['.\\data\\WRDS_Financial_Ratios_Monthly\\WRDS_Financial_Ratios_Monthly.csv',\n",
    "                 #'\\data\\WRDS_ALL_PRICE_RETURN_DATA_Daily\\WRDS_ALL_PRICE_RETURN_DATA_Daily.csv',\n",
    "                  '.\\data\\WRDS_ALL_PRICE_RETURN_DATA_Monthly\\WRDS_ALL_PRICE_RETURN_DATA_Monthly.csv',\n",
    "                   '.\\data\\WRDS_constiuents1968_2020_output_universe\\WRDS_constiuents1968_2020_output_universe.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituents = pd.read_csv(data_filenames[2], '\\t',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituents['DLSTDT'] = np.where(constituents['DLSTDT']==20191231,20201031,constituents['DLSTDT'])\n",
    "constituents['NAMEDT'] = pd.to_datetime(constituents['NAMEDT'],format=\"%Y%m%d\")\n",
    "constituents['BEGEXCHDATE'] = pd.to_datetime(constituents['BEGEXCHDATE'],format=\"%Y%m%d\")\n",
    "constituents['ENDEXCHDATE'] = pd.to_datetime(constituents['ENDEXCHDATE'],format=\"%Y%m%d\")\n",
    "constituents['DLSTDT'] = pd.to_datetime(constituents['DLSTDT'],format=\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = pd.date_range('1968-01-31','2020-10-31', freq='M').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame()\n",
    "universe = pd.DataFrame(columns=constituents.columns)\n",
    "for dt in date_list:\n",
    "    print(dt)\n",
    "    temp = constituents[(constituents['BEGEXCHDATE'] <= dt) & (constituents['DLSTDT'] >= dt)]\n",
    "    temp['DATE'] = dt\n",
    "    print(temp.shape[0])\n",
    "    universe = universe.append(temp)\n",
    "    del temp \n",
    "    temp = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe.to_csv('./universe_files/initial_universe.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del constituents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>After initial Universe</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe=pd.read_csv('./universe_files/initial_universe.csv',low_memory=False,dtype={'PERMNO':'string', 'NCUSIP':'string', 'DATE':'string', 'PERMCO':'string','TICKER':'string', 'NCUSIP':'string'})\n",
    "universe['DATE'] = pd.to_datetime(universe['DATE'],format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = pd.date_range('1968-01-31','2020-10-31', freq='M').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_ratios = pd.read_csv('.\\data\\WRDS_Financial_Ratios_Monthly\\WRDS_Financial_Ratios_Monthly.csv','\\t',low_memory=False,index_col=0,dtype={'gvkey':'string', 'permno':'string', 'adate':'string', 'qdate':'string', 'public_date':'string','TICKER':'string', 'cusip':'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_ratios['public_date'] = pd.to_datetime(financial_ratios['public_date'],format=\"%Y%m%d\")\n",
    "financial_ratios['divyield'] = financial_ratios['divyield'].str.rstrip('%').astype('float') / 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe = pd.merge(universe, financial_ratios, how='left', left_on=['DATE','PERMNO'], right_on = ['public_date','permno'], suffixes=['_PERMNO', '_permno'],copy=False)\n",
    "universe.to_csv('./universe_files/financial_ratios_universe_1.csv',index=False)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe = pd.merge(universe, financial_ratios,  how='left', left_on=['DATE','NCUSIP'], right_on = ['public_date','cusip'], suffixes=['_NCUSIP', '_cusip'],copy=False)\n",
    "universe.to_csv('./universe_files/financial_ratios_universe_2.csv',index=False)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del financial_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "date_list = pd.date_range('1968-01-31','2020-10-31', freq='M').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe=pd.read_csv('./universe_files/financial_ratios_universe_2.csv',low_memory=False)\n",
    "universe['DATE'] = pd.to_datetime(universe['DATE'],format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame()\n",
    "for dt in date_list:\n",
    "    print(dt)\n",
    "    temp_df = pd.DataFrame((~universe[universe['DATE']==dt].isna()).sum()).T\n",
    "    temp_df.index = [dt]\n",
    "    summary = summary.append(temp_df)\n",
    "    del temp_df\n",
    "    gc.collect()\n",
    "    temp_df = pd.DataFrame()\n",
    "summary.to_csv('./universe_files/summary_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe = universe[((universe['DATE']>'1969-12-31')&(universe['DATE']<'2020-1-31'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe = universe.dropna(axis=1, how='all')\n",
    "universe.to_csv('./universe_files/financial_ratios_universe_3.csv',index=False,low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe=pd.read_csv('./universe_files/financial_ratios_universe_3.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_cols = ['DATE','COMNAM','NCUSIP','cusip_NCUSIP','cusip_cusip','PERMNO','permno_cusip','permno_NCUSIP','PERMCO','SICCD','TICKER','TICKER_PERMNO','TICKER_permno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_cols = ['accrual','adv_sale','aftret_eq','aftret_equity','aftret_invcapx','at_turn','bm','CAPEI','capital_ratio','cash_conversion','cash_debt','cash_lt','cash_ratio','cfm','curr_debt','curr_ratio','de_ratio','debt_assets','debt_at','debt_capital','debt_ebitda','debt_invcap','divyield','dltt_be','dpr','efftax','equity_invcap','evm','fcf_ocf','gpm','GProf','int_debt','int_totdebt','intcov','intcov_ratio','inv_turn','invt_act','lt_debt','lt_ppent','npm','ocf_lct','opmad','opmbd','pay_turn','pcf','pe_exi','pe_inc','pe_op_basic','pe_op_dil','PEG_1yrforward','PEG_ltgforward','PEG_trailing','pretret_earnat','pretret_noa','profit_lct','ps','ptb','ptpm','quick_ratio','rd_sale','rect_act','rect_turn','roa','roce','roe','sale_equity','sale_invcap','sale_nwc','short_debt','staff_sale','totdebt_invcap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_univ = universe[main_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in second_cols:\n",
    "    clean_univ[col] = np.where(universe[col+'_cusip'].isna(),universe[col+'_NCUSIP'],universe[col+'_cusip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_univ.to_csv('./universe_files/financial_ratios_universe_4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame()\n",
    "for dt in date_list:\n",
    "    print(dt)\n",
    "    temp_df = pd.DataFrame((~clean_univ[clean_univ['DATE']==dt].isna()).sum()).T\n",
    "    temp_df = temp_df/(temp_df.values.max())\n",
    "    temp_df.index = [dt]\n",
    "    summary = summary.append(temp_df)\n",
    "    del temp_df\n",
    "    gc.collect()\n",
    "    temp_df = pd.DataFrame()\n",
    "summary.to_csv('./universe_files/summary_data_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame((~clean_univ[clean_univ['DATE']==dt].isna()).sum()).T\n",
    "temp_df = temp_df/(temp_df.values.max())\n",
    "temp_df.index = [dt]\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = pd.date_range('1970-01-31','2019-12-31', freq='M').tolist()\n",
    "for dt in date_list:\n",
    "    print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_univ[clean_univ[second_cols].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(list1): \n",
    "      \n",
    "    # insert the list to the set \n",
    "    list_set = set(list1) \n",
    "    # convert the set to the list \n",
    "    unique_list = (list(list_set)) \n",
    "    return unique_list\n",
    "\n",
    "pd.DataFrame(unique(list(clean_univ[clean_univ[second_cols].isna().sum(axis=1)>70]['PERMNO']))).to_csv('permno_codes.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_univ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillna = pd.read_csv('D:\\\\Project\\\\e4040-2020Fall-Project-WNZH-jr4001-xy2419-gl2664\\\\fillna.txt','\\t',low_memory=False, dtype={'PERMNO':'string', 'NCUSIP':'string', 'DATE':'string', 'PERMCO':'string','TICKER':'string', 'gvkey':'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillna['public_date'] = pd.to_datetime(fillna['public_date'],format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_univ = clean_univ.merge(fillna,  how='left', left_on=['DATE','PERMNO'], right_on = ['public_date','permno'], suffixes=['_original', '_copy'],copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(clean_univ.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_cols = ['DATE','COMNAM','NCUSIP','cusip_NCUSIP','cusip_cusip','cusip','PERMNO','permno_cusip','permno_NCUSIP','permno','PERMCO','SICCD','TICKER_original','TICKER_PERMNO','TICKER_permno','TICKER_copy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_cols = ['accrual','adv_sale','aftret_eq','aftret_equity','aftret_invcapx','at_turn','bm','CAPEI','capital_ratio','cash_conversion','cash_debt','cash_lt','cash_ratio','cfm','curr_debt','curr_ratio','de_ratio','debt_assets','debt_at','debt_capital','debt_ebitda','debt_invcap','divyield','dltt_be','dpr','efftax','equity_invcap','evm','fcf_ocf','gpm','GProf','int_debt','int_totdebt','intcov','intcov_ratio','inv_turn','invt_act','lt_debt','lt_ppent','npm','ocf_lct','opmad','opmbd','pay_turn','pcf','pe_exi','pe_inc','pe_op_basic','pe_op_dil','PEG_1yrforward','PEG_ltgforward','PEG_trailing','pretret_earnat','pretret_noa','profit_lct','ps','ptb','ptpm','quick_ratio','rd_sale','rect_act','rect_turn','roa','roce','roe','sale_equity','sale_invcap','sale_nwc','short_debt','staff_sale','totdebt_invcap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_clean_univ = clean_univ[main_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in second_cols:\n",
    "    new_clean_univ[col] = np.where(clean_univ[col+'_original'].isna(),clean_univ[col+'_copy'],clean_univ[col+'_original'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_clean_univ.to_csv('./universe_files/financial_ratios_universe_5.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame()\n",
    "for dt in date_list:\n",
    "    print(dt)\n",
    "    temp_df = pd.DataFrame((~new_clean_univ[new_clean_univ['DATE']==dt].isna()).sum()).T\n",
    "    temp_df = temp_df/(temp_df.values.max())\n",
    "    temp_df.index = [dt]\n",
    "    summary = summary.append(temp_df)\n",
    "    del temp_df\n",
    "    gc.collect()\n",
    "    temp_df = pd.DataFrame()\n",
    "summary.to_csv('./universe_files/summary_data_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
